[{"content":"Skills Python C/C++ Go Linux Kubernetes Docker OpenShift Helm Automation AWS CI/CD GitLab Terraform\nDescription Maintained complete ownership of AWS cloud resources using Terraform, ensuring scalable and consistent infrastructure management across environments. Designed and implemented robust CI/CD pipelines for building, testing, and deploying applications across multi-cloud environments, including Amazon EKS and OpenShift clusters on IBM Cloud. Developed end-to-end pipelines that build Docker images, generate Helm charts, and execute multi-stage testing across various QAT environments in EKS. Implemented and managed GitLab CI/CD pipelines to automate the build, test, and deployment processes for multiple projects. Utilized Terraform to provision and manage AWS infrastructure, ensuring scalability, reliability, and cost-effectiveness. Integrated Terraform scripts into GitLab pipelines, automating the deployment and configuration of infrastructure as part of the continuous integration process. Collaborated with the team to define CI/CD best practices, including the use of Infrastructure as Code (IaC) via Terraform, to enhance reproducibility and consistency in the SDLC. Configured and maintained GitLab Runners for efficient parallelized builds, optimizing pipeline performance. Worked closely with other developers to troubleshoot build failures, resolve integration issues, and enhance overall pipeline reliability. Took responsibility for security across cloud environments and code dependencies by implementing automated monitoring, incident response pipelines, and AWS Lambda functions. Integrated security scanning tools into CI/CD pipelines to ensure code quality and identify vulnerabilities early in the development process. Created and maintained documentation for CI/CD processes and Terraform configurations, enabling effective knowledge transfer and smoother onboarding. Developed a Python-based AWS Lambda function and deployed it using Terraform and GitLab pipelines, contributing to deployment automation and operational efficiency. Coordinated directly with clients to streamline and support smoother deployments on their infrastructure. Created lightweight CLI tools in Go for both local development and GitLab pipelines, enhancing developer productivity and standardizing routine tasks. ","permalink":"https://arunaideepan.github.io/experience/lightcast/","summary":"Skills Python C/C++ Go Linux Kubernetes Docker OpenShift Helm Automation AWS CI/CD GitLab Terraform\nDescription Maintained complete ownership of AWS cloud resources using Terraform, ensuring scalable and consistent infrastructure management across environments. Designed and implemented robust CI/CD pipelines for building, testing, and deploying applications across multi-cloud environments, including Amazon EKS and OpenShift clusters on IBM Cloud. Developed end-to-end pipelines that build Docker images, generate Helm charts, and execute multi-stage testing across various QAT environments in EKS.","title":"Software Engineer"},{"content":"Description Set up an OpenStack Ussuri minimal environment consisting of two nodes (controller and compute node) for team members\u0026rsquo; training purposes. Configured and deployed OpenStack services on the controller and compute nodes. Implemented network configurations and security settings to ensure the stability and security of the OpenStack environment. Collaborated with colleagues to troubleshoot issues and optimize the performance of the OpenStack setup. Skills Python Bash Linux Databases Openstack\n","permalink":"https://arunaideepan.github.io/experience/checktronix/","summary":"Description Set up an OpenStack Ussuri minimal environment consisting of two nodes (controller and compute node) for team members\u0026rsquo; training purposes. Configured and deployed OpenStack services on the controller and compute nodes. Implemented network configurations and security settings to ensure the stability and security of the OpenStack environment. Collaborated with colleagues to troubleshoot issues and optimize the performance of the OpenStack setup. Skills Python Bash Linux Databases Openstack","title":"Software Engineer Intern"},{"content":"Ever pushed a new Docker image with the same tag, deployed it, and‚Ä¶ nothing changed? Yep. Been there. Here\u0026rsquo;s what I found out - and a really cool tool I wish worked on OpenShift.\nSo\u0026hellip; Why Isn‚Äôt My New Code Showing Up? Let‚Äôs set the scene. You‚Äôre working on OpenShift, you build a new image with the same tag (v1.0.0, latest, whatever), push it, redeploy, and your app is still doing the old stuff.\nIt‚Äôs one of those classic ‚Äúwhat the hell is going on?‚Äù moments.\nTurns out - it‚Äôs all about image caching, and OpenShift is playing by its own rules (for good reasons).\nThe Real Reason: OpenShift Caches Images (and It‚Äôs Not a Bug) Here‚Äôs the deal: OpenShift (like Kubernetes in general) doesn\u0026rsquo;t automatically pull updated images with the same tag unless you tell it to.\nTL;DR: If the image tag is latest: OpenShift sets imagePullPolicy: Always Any other tag?: It defaults to IfNotPresent, meaning ‚Äúdon‚Äôt pull again if I already have this tag locally.‚Äù So when you push a new image with v1.0.0, OpenShift is like: ‚ÄúCool, I already have v1.0.0 cached. I‚Äôm good.‚Äù And your changes? Nowhere in sight.\nOpenShift Docs: Managing container images\nWhy This Actually Makes Sense (But Still Hurts) This behavior isn‚Äôt dumb - it‚Äôs deliberate:\nFaster pod startup Reduced registry bandwidth Lower pull costs More reliable startup when the registry is flaky It‚Äôs just not what you expect when you\u0026rsquo;re in the middle of debugging and nothing looks like it\u0026rsquo;s changing.\nThen I Found Spegel‚Ä¶ on YouTube So there I was, doing the usual late-night YouTube spiral, when I randomly stumbled across Spegel in this video titled Microsoft Tried To Steal A Project And Almost Got Away With It\u0026hellip; - and yeah, it got interesting real fast. A cool open-source project github.com/spegel-org/spegel\nIt does something clever: turns your cluster into a peer-to-peer image-sharing network. Every node becomes a tiny registry, so when one node has the image, others can grab it from there - no need to go to an external registry every time.\nHere‚Äôs what caught my attention:\nSuper fast deployments (especially for larger images) Cluster-wide image caching Reduces external registry hits Works transparently with existing workflows Why Spegel Isn\u0026rsquo;t Available in OpenShift Now here‚Äôs the twist.\nI got super excited, then realized\u0026hellip; Spegel doesn\u0026rsquo;t work on OpenShift. And here\u0026rsquo;s why:\nIt‚Äôs all about container runtimes: containerd vs CRI-O Spegel depends on containerd to manage the local image cache and registry mirroring. OpenShift uses CRI-O as its default container runtime - chosen for its Kubernetes focus, tight SELinux integration, and security posture. While containerd is a CNCF project with rich features for pluggable registries, CRI-O is much more minimal and doesn\u0026rsquo;t expose the same image-layer APIs that Spegel hooks into.\nWhy OpenShift uses CRI-O\nSo, unless OpenShift shifts to containerd (which is unlikely), tools like Spegel just aren\u0026rsquo;t compatible out-of-the-box.\nOpenShift\u0026rsquo;s More Traditional Approach OpenShift‚Äôs image caching is still pretty robust, just‚Ä¶ different. It leans on:\nImage streams: OpenShift‚Äôs own abstraction for managing image tags and versions OpenShift Docs: Image Streams Immutable tags: You should really stop reusing the same tag for different images üòÖ Explicit pull policies: You can override the default caching by doing this: spec: containers: - name: myapp image: myregistry.com/myapp:v1.0.0 imagePullPolicy: Always Or better, just use unique tags for every build:\npodman build -t myapp:${GIT_COMMIT} . podman push myapp:${GIT_COMMIT} Spegel‚Äôs Peer-to-Peer Vibes If you\u0026rsquo;re running vanilla Kubernetes or something like K3s with containerd, Spegel is amazing. It gives you:\nInstant image access across the cluster Automatic optimization Registry-free local pulls Zero-cost bandwidth reuse No more waiting for a 1GB image to pull for the 20th time from Docker Hub.\nSpegel GitHub Project\nFinal Thoughts: Two Philosophies, Two Worlds This whole deep dive showed me how OpenShift and Spegel represent two very different takes on the same problem:\nOpenShift: The ‚ÄúStable, Predictable‚Äù Way Relies on tags being immutable Optimized for enterprise-grade stability Makes developers responsible for versioning and caching logic Spegel: The ‚ÄúFast and Distributed‚Äù Way Cluster becomes its own mini-registry Smart and automatic caching via P2P Geared for speed, resilience, and cost reduction TL;DR: What You Can Do on OpenShift Don‚Äôt reuse tags - Use something like a Git SHA or timestamp Set imagePullPolicy: Always when you really need to force an update Leverage ImageStreams if you‚Äôre doing tag promotion workflows Understand your runtime - tools like Spegel won‚Äôt work with CRI-O Would I Use Spegel? Absolutely, if I were running containerd-based clusters. It‚Äôs clever, fast, and fits well in test/staging or self-hosted production.\nBut for OpenShift? It‚Äôs not the right tool. And that‚Äôs fine. OpenShift gives me a more secure, enterprise-grade runtime and tools like ImageStreams that, once you get used to them, work pretty well.\nSometimes the trade-offs are worth it.\n","permalink":"https://arunaideepan.github.io/blog/blog-2/","summary":"Ever pushed a new Docker image with the same tag, deployed it, and‚Ä¶ nothing changed? Yep. Been there. Here\u0026rsquo;s what I found out - and a really cool tool I wish worked on OpenShift.\nSo\u0026hellip; Why Isn‚Äôt My New Code Showing Up? Let‚Äôs set the scene. You‚Äôre working on OpenShift, you build a new image with the same tag (v1.0.0, latest, whatever), push it, redeploy, and your app is still doing the old stuff.","title":"What I Learned About Image Caching From a YouTube Rabbit Hole: OpenShift vs Spegel"},{"content":"LD_PRELOAD: Unleashing Your Inner Linux Wizardüêß Imagine having a superpower that lets you secretly modify how any program runs, without touching its source code. Welcome to the wild world of LD_PRELOAD, the coolest trick in the Linux hacker\u0026rsquo;s toolkit!\nWhat the Heck is LD_PRELOAD? Think of LD_PRELOAD as a sneaky library loader that whispers to your system, \u0026ldquo;Hey, I want to intercept and modify library calls before the program even knows what\u0026rsquo;s happening.\u0026rdquo; It\u0026rsquo;s like being a digital ninja, silently modifying program behavior.\nHow Does This Magic Work? When you set LD_PRELOAD, you\u0026rsquo;re telling the dynamic linker: \u0026ldquo;Load my library first, before any other libraries.\u0026rdquo; This means:\nYour custom library gets priority You can override system functions You can add superpowers to existing programs Technical Deep Dive: Dynamic Linking Explained Before diving into the code, let\u0026rsquo;s understand how dynamic linking works:\nDynamic Linker (ld.so): Responsible for loading shared libraries at runtime Symbol Resolution: Finds and links function calls to their correct implementations Library Search Path: /etc/ld.so.conf LD_LIBRARY_PATH environment variable Default system paths Simple example Let\u0026rsquo;s dive deep into a practical example of LD_PRELOAD that demonstrates its true power. We\u0026rsquo;ll create a program that secretly injects a joke into every printf call without modifying the original source code!\nThe Code Breakdown // interceptor.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdarg.h\u0026gt; #include \u0026lt;dlfcn.h\u0026gt; // define a function pointer type for printf typedef int (*printf_func)(const char *format, ...); int printf(const char *format, ...) { // dynamic loading of the real printf static printf_func real_printf = NULL; if (!real_printf) { void *handle = dlopen(\u0026#34;libc.so.6\u0026#34;, RTLD_LAZY); real_printf = dlsym(handle, \u0026#34;printf\u0026#34;); } // prepare variadic arguments va_list args; va_start(args, format); // call the original printf int result = real_printf(format, args); // inject our programmer joke real_printf(\u0026#34;\\nWhich body part does a programmer know best?\\nA: ARM\\n\u0026#34;); va_end(args); return result; } Let\u0026rsquo;s Break Down the program Dynamic Function Interception\nWe create a custom printf function that looks exactly like the system\u0026rsquo;s printf dlopen() and dlsym() are used to find the original printf function This allows us to call the original function while adding our own twist Variadic Argument Handling\nva_list, va_start(), and va_end() let us handle functions with variable arguments This is crucial for intercepting printf, which can take any number of arguments Compilation Incantation\ngcc -shared -fPIC interceptor.c -o funprintf.so -ldl -shared: Create a shared library -fPIC: Position Independent Code (required for shared libraries) -ldl: Link against the dynamic loading library Practical Spell Casting üßô‚Äç‚ôÇÔ∏è To use our magic:\n// test-printf.c #include \u0026lt;stdio.h\u0026gt; int main(){ printf(\u0026#34;hello\u0026#34;); return 0; } gcc -shared -fPIC interceptor.c -o funprintf.so -ldl # complie test program gcc test-printf.c -o test export LD_PRELOAD=./funprintf.so # run with our printf interceptor ./test hello Which body part does a programmer know best? A: ARM Under the Hood: What\u0026rsquo;s Really Happening? The dynamic linker loads our library first Our printf function gets called instead of the system\u0026rsquo;s We execute the original printf Then we sneak in our joke Practical Use Cases Debugging:\nInject logging without source code modification Override error handling Create custom error reporting mechanisms Security and Monitoring:\nTrack function calls Intercept system calls to log activities Create custom access controls Implement lightweight sandboxing Humor Injection: As demonstrated (most important, obviously!)\nPerformance Profiling:\nMeasure function execution times Track resource usage Create custom profiling tools Legacy System Modifications: Add features without recompiling\nSafety and Caution Intercepting system calls can lead to unexpected behavior, May break application functionality. Security implications if not carefully implemented Use for learning, debugging and fun, not in production systems Limitations and Considerations Not all functions can be easily intercepted Works best with C and dynamically linked libraries Performance overhead Requires deep understanding of system internals The Hacker\u0026rsquo;s Wisdom LD_PRELOAD isn\u0026rsquo;t just a technique; it\u0026rsquo;s a mindset. It\u0026rsquo;s about understanding systems so deeply that you can reshape them from the inside.\nPro Tip: With great power comes great responsibility. Start small, experiment safely, and always have a backup!\n","permalink":"https://arunaideepan.github.io/blog/blog-1/","summary":"LD_PRELOAD: Unleashing Your Inner Linux Wizardüêß Imagine having a superpower that lets you secretly modify how any program runs, without touching its source code. Welcome to the wild world of LD_PRELOAD, the coolest trick in the Linux hacker\u0026rsquo;s toolkit!\nWhat the Heck is LD_PRELOAD? Think of LD_PRELOAD as a sneaky library loader that whispers to your system, \u0026ldquo;Hey, I want to intercept and modify library calls before the program even knows what\u0026rsquo;s happening.","title":"LD_PRELOAD - The Linux Hack That Feels Like Black Magic"}]